{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "  return np.multiply(x, (1 - x))\n",
    "\n",
    "def loss(y, predicted):\n",
    "    return np.mean((y - predicted)**2)\n",
    "  \n",
    "def xavier_initialization(i,o):\n",
    "  a = np.sqrt(6.0/(i+o))\n",
    "  return 2 * a * np.random.random((i,o)) - a\n",
    "\n",
    "def xavier_initialization_hidden(i,o,h):\n",
    "  a = np.sqrt(6.0/(i+o))\n",
    "  return 2 * a * np.random.random((i,o,h)) - a\n",
    "\n",
    "def add_bias(X):\n",
    "  return np.concatenate((np.ones((np.shape(X)[0], 1)), X), axis=1)\n",
    "\n",
    "class ANN:\n",
    "  def __init__(self, h, s):\n",
    "    self.h = h\n",
    "    self.s = s\n",
    "    self.input_synapse = np.empty((0,0))\n",
    "    self.hidden_synapse = np.empty((0,0))\n",
    "    self.output_synapse = np.empty((0,0))\n",
    "  \n",
    "  def fit(self, X, y, alpha, t):    \n",
    "    h = self.h\n",
    "    s = self.s\n",
    "    X = add_bias(X)\n",
    "    \n",
    "    self.input_synapse = xavier_initialization(X.shape[1],s)\n",
    "    self.hidden_synapse = xavier_initialization_hidden(s+1,s,h)\n",
    "    self.output_synapse = xavier_initialization(s+1,y.shape[1])   \n",
    "    \n",
    "    #print(X.shape)\n",
    "    #print(self.input_synapse.shape)\n",
    "    #print(self.hidden_synapse[:,:,0].shape)\n",
    "    #print(self.output_synapse.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    for i in range(t):      \n",
    "      input_layer = X\n",
    "      hidden_layer = np.ones([input_layer.shape[0],s+1,h]) \n",
    "      hidden_layer[:,1:,0] = sigmoid(np.dot(input_layer,self.input_synapse))\n",
    "            \n",
    "      j = 1\n",
    "      while(j < h):\n",
    "        hidden_layer[:,1:,j] = sigmoid(np.dot(hidden_layer[:,:,j-1],self.hidden_synapse[:,:,j-1]))\n",
    "        j += 1\n",
    "\n",
    "      output_layer = sigmoid(np.dot(hidden_layer[:,:,h-1],self.output_synapse))\n",
    "\n",
    "      #Back Propogation\n",
    "      output_error = output_layer - y\n",
    "      output_delta = output_error * sigmoid_derivative(output_layer)\n",
    "\n",
    "      hidden_error = np.empty([input_layer.shape[0],s+1,h]) \n",
    "      hidden_delta = np.empty([input_layer.shape[0],s+1,h]) \n",
    "\n",
    "      hidden_error[:,:,h-1] = output_delta.dot(self.output_synapse.T)\n",
    "      hidden_delta[:,:,h-1] = hidden_error[:,:,h-1] * sigmoid_derivative(hidden_layer[:,:,h-1])\n",
    "\n",
    "      j -= 2\n",
    "      while(j >= 0):\n",
    "        hidden_error[:,:,j] = hidden_delta[:,1:,j+1].dot(self.hidden_synapse[:,:,j].T)\n",
    "        hidden_delta[:,:,j] = hidden_error[:,:,j] * sigmoid_derivative(hidden_layer[:,:,j])\n",
    "        j -= 1\n",
    "      \n",
    "      #input_error = hidden_delta[:,1:,0].dot(input_synapse.T)\n",
    "      #input_delta = input_error * sigmoid_derivative(input_layer)\n",
    "      \n",
    "      self.input_synapse -= alpha * (input_layer.T.dot(hidden_delta[:,1:,0]))\n",
    "\n",
    "      j += 1\n",
    "      while(j < h-1):\n",
    "        self.hidden_synapse[:,:,j] -= alpha * (hidden_layer[:,:,j].T.dot(hidden_delta[:,1:,j+1]))\n",
    "        j += 1\n",
    "\n",
    "      self.output_synapse -= alpha * (hidden_layer[:,:,h-1].T.dot(output_delta))\n",
    "\n",
    "      if(i % 100 == 0): \n",
    "        print(\"Iterations: \" + str(i)  + \" Loss: \" + str(loss(y,output_layer)))\n",
    "  \n",
    "  def predict(self, T):\n",
    "    h = self.h\n",
    "    s = self.s\n",
    "    T = add_bias(T)\n",
    "    \n",
    "    input_layer = T\n",
    "    hidden_layer = np.ones([input_layer.shape[0],s+1,h])\n",
    "    hidden_layer[:,1:,0] = sigmoid(np.dot(input_layer,self.input_synapse))\n",
    "\n",
    "    j = 1\n",
    "    while(j < h):\n",
    "      hidden_layer[:,1:,j] = sigmoid(np.dot(hidden_layer[:,:,j-1],self.hidden_synapse[:,:,j-1]))\n",
    "      j += 1   \n",
    "    \n",
    "    output_layer = sigmoid(np.dot(hidden_layer[:,:,h-1],self.output_synapse))\n",
    "    return output_layer\n",
    "  \n",
    "  def print(self):\n",
    "    for w in self.input_synapse:\n",
    "      print(w)\n",
    "    for w in self.hidden_synapse:\n",
    "      print(w)\n",
    "    for w in self.output_synapse:\n",
    "      print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadUmair\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0 Loss: 0.260706672793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadUmair\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0 Loss: 0.212564160772\n",
      "Iterations: 0 Loss: 0.265582945459\n",
      "Error estimate from 3-fold validation is 0.468164751547\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "\n",
    "def calculate_error(t, v, h, s, iterations):\n",
    "  X = np.array(t.iloc[0:,1:])\n",
    "  X = StandardScaler().fit_transform(X)\n",
    "  y = pd.get_dummies(t.iloc[0:,0]).as_matrix()\n",
    "  T = np.array(v.iloc[0:,1:])\n",
    "  y_actual = v.iloc[0:,0].as_matrix()\n",
    "  \n",
    "  ann = ANN(h, s)\n",
    "  ann.fit(X, y, .0001, iterations)\n",
    "  \n",
    "  output_layer = ann.predict(T)  \n",
    "  y_predicted = np.argmax(output_layer, axis=1)\n",
    "  \n",
    "  return 1 - np.sum(y_predicted==y_actual)/len(y_actual)\n",
    "\n",
    "df = pd.read_csv('data/train.csv', sep=\",\",\n",
    "                 header=0, quoting=0, low_memory=False)\n",
    "\n",
    "partition = floor(len(df) / 3)\n",
    "a = df[0:partition]\n",
    "b = df[partition: 2 * partition + 1]\n",
    "c = df[2 * partition + 1: 3 * partition + 2]\n",
    "\n",
    "frames = [a, b]\n",
    "t1 = pd.concat(frames)\n",
    "v1 = c\n",
    "\n",
    "frames = [b, c]\n",
    "t2 = pd.concat(frames)\n",
    "v2 = a\n",
    "\n",
    "frames = [a, c]\n",
    "t3 = pd.concat(frames)\n",
    "v3 = b\n",
    "\n",
    "h=1\n",
    "s=50\n",
    "iterations=11\n",
    "e1 = calculate_error(t1, v1, h, s, iterations)\n",
    "e2 = calculate_error(t2, v2, h, s, iterations)\n",
    "e3 = calculate_error(t3, v3, h, s, iterations)\n",
    "print(\"Error estimate from 3-fold validation is \" + str(np.mean([e1,e2,e3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadUmair\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#X = np.array([[0,0,1],[0,1,1],[1,0,1],[0,0,0]])\n",
    "#X = np.array([[0,1]])\n",
    "#y = pd.get_dummies(np.array([0,1,1,1]).T).as_matrix()\n",
    "#T = np.array([[1,1,1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
